{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataExploration and Photo Level and Business level Feature Extraction Phase:-\n",
    "\n",
    "This is photo level feature extraction and Business feature extraction step Using Inception-v3  pre-trained Classification model.Also we can use model from scratch but it will take long time to train also accuracy is bit low compare to pre-trained models.By using weights of Inception-v3 pretrained model  which was trained on ImageNet to will extract bottleneck features of Yelp photos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from PIL import Image\n",
    "from PIL import ImageFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths of train & test photos\n",
    "train_path = \"../input/data/train_photos/\"\n",
    "test_path = \"../input/data/test_photos/\"\n",
    "\n",
    "# Paths of CSV files\n",
    "train_pid_bid = '../input/data/train_photo_to_biz_ids.csv'\n",
    "train_bid_label = '../input/data/train.csv'\n",
    "test_pid_bid = '../input/data/test_photo_to_biz.csv'\n",
    "\n",
    "# Make dataframes \n",
    "train_photos = pd.read_csv(train_pid_bid)\n",
    "train_label = pd.read_csv(train_bid_label)\n",
    "train_id = pd.read_csv(train_pid_bid) \n",
    "test_photos = pd.read_csv(test_pid_bid)\n",
    "\n",
    "# Labels dictionary\n",
    "label_notation = {0: 'good_for_lunch', 1: 'good_for_dinner', 2: 'takes_reservations',  3: 'outdoor_seating',\n",
    "                  4: 'restaurant_is_expensive', 5: 'has_alcohol', 6: 'has_table_service', 7: 'ambience_is_classy',\n",
    "                  8: 'good_for_kids'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train...\")\n",
    "# Show 25 images in train set\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for x in range(25):\n",
    "        plt.subplot(5, 5, x+1)\n",
    "        im = Image.open(train_path + str(train_photos.photo_id[x]) + '.jpg')\n",
    "        im = im.resize((192, 192), Image.ANTIALIAS)\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Test...\")\n",
    "# Show 25 images in test set\n",
    "plt.rcParams['figure.figsize'] = (10.0, 10.0)\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "for x in range(25):\n",
    "        plt.subplot(5, 5, x+1)\n",
    "        im = Image.open(test_path +  str(test_photos.photo_id[x]) + '.jpg')\n",
    "        im = im.resize((192, 192), Image.ANTIALIAS)\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing images for each label in training dataset for Analysis using matplot lib subplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show 9 images belonged to each label\n",
    "for l in label_notation:\n",
    "    ids = train_attr[train_attr['labels'].str.contains(str(l))==True].business_id.tolist()[:9]\n",
    "    plt.rcParams['figure.figsize'] = (7.0, 7.0)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    for x in range(9):\n",
    "        plt.subplot(3, 3, x+1)\n",
    "        im = Image.open(train_path + str(train_photos.photo_id[ids[x]]) + '.jpg')\n",
    "        im = im.resize((192, 192), Image.ANTIALIAS)\n",
    "        plt.imshow(im)\n",
    "        plt.axis('off')\n",
    "    fig = plt.figure()\n",
    "    fig.suptitle(label_notation[l])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm # Enable progress bar\n",
    "from keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions # Load pre-trained model\n",
    "from keras.models import Model\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Flatten, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evolution Of Convolution neural networks And Importance of using InceptionV3.\n",
    "\n",
    "1.VGG16 and VGG19\n",
    "\n",
    "This are two major drawbacks with VGGNet:\n",
    "    It is painfully slow to train.\n",
    "    The network architecture weights themselves are quite large (in terms of disk/bandwidth)\n",
    "We still use VGG in many deep learning image classification problems.However, smaller network architectures are often more desirable (such as SqueezeNet, GoogLeNet, etc.).\n",
    "\n",
    "2.resnet50\n",
    "\n",
    "network-in-network architectures.\n",
    "\n",
    "Draw back of resnet 50 model:- \n",
    "\n",
    "1.Even though ResNet is much deeper than VGG16 and VGG19, the model size is actually substantially smaller due to the usage of global average pooling rather than fully-connected layers — this reduces the model size down to 102MB for ResNet50.\n",
    "\n",
    "3.Inception V3 Advantages compare to resnet:-\n",
    "\n",
    "The goal of the inception module is to act as a “multi-level feature extractor” by computing 1×1, 3×3, and 5×5 convolutions within the same module of the network \n",
    "\n",
    "The weights for Inception V3 are smaller than both VGG and ResNet, coming in at 96MB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# Use InceptionV3 model to extract bottleneck features\n",
    "#ResNet_model = ResNet50(weights='imagenet', include_top = False)\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "# Construct a feature extractor based on pre-trained model\n",
    "input = Input(shape=(224, 224, 3), name='image_input')\n",
    "feature_extractor = base_model(input)\n",
    "flattener = Flatten()(feature_extractor)\n",
    "bottleneck_feature_extractor = Model(inputs=input, outputs=flattener)\n",
    "\n",
    "# Empty arrays for storing extracted features\n",
    "X_train = []; X_test = []\n",
    "\n",
    "# Extract bottleneck features of photos for traninig\n",
    "for i in tqdm(range(len(train_photos))):\n",
    "    img_path = train_path + str(train_photos.photo_id[i]) + '.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "\n",
    "    bottleneck_features_train_raw = bottleneck_feature_extractor.predict(x)\n",
    "    bottleneck_features_train_reduced =  bottleneck_features_train_raw.squeeze()\n",
    "    X_train.append(bottleneck_features_train_reduced)\n",
    "\n",
    "# Extract bottleneck features of photos for testing    \n",
    "for i in tqdm(range(len(test_photos))):\n",
    "    img_path = test_path + str(test_photos.photo_id[i]) + '.jpg'\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = preprocess_input(x)\n",
    "    \n",
    "    bottleneck_features_test_raw = bottleneck_feature_extractor.predict(x)\n",
    "    bottleneck_features_test_reduced =  bottleneck_features_test_raw.squeeze()\n",
    "    X_test.append(bottleneck_features_test_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Feature Extraction phase we need to concatinate features to photo_id.By Using pandas merged features and photo_ids in file name train_merge.csv and test_merge.csv file so that we can integrate to the Business model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With extracted features, make a new train set by concatenating with photo_id in an original train set \n",
    "bottleneck_features_train = pd.DataFrame({'features' : X_train})\n",
    "train_merge = pd.concat([bottleneck_features_train, train_photos], axis=1)\n",
    "train_merge.to_pickle('train_merge.csv') # Save in pickle for preserving array format and considering its size\n",
    "\n",
    "# With extracted features, make a new test set by concatenating with photo_id in an original test set \n",
    "bottleneck_features_test = pd.DataFrame({'features' : X_test})\n",
    "test_merge = pd.concat([bottleneck_features_test, test_photos], axis=1)\n",
    "test_merge.to_pickle('test_merge.csv') # Save in pickle for preserving array format and considering its size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading data\n",
    "train_merge = pd.read_pickle('train_merge.csv')\n",
    "test_merge = pd.read_pickle('test_merge.csv')\n",
    "\n",
    "# Check if the data frame is loaded normally\n",
    "test_merge.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2. Business feature manipulation\n",
    "\n",
    "Feature pooling(mean,midean):This Method is Basically intended to Extract average features of photos in training set and test set  that are assigned to same business_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bid_features = pd.DataFrame(train_merge.groupby('business_id')['features'].apply(np.mean))\n",
    "train_bid_features.reset_index(level=0, inplace=True)\n",
    "\n",
    "test_bid_features = pd.DataFrame(test_merge.groupby('business_id')['features'].apply(np.mean))\n",
    "test_bid_features.reset_index(level=0, inplace=True)\n",
    "\n",
    "test_bid_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort labels by business_id in an ascending order, and then merge the label with mean feature of each business id\n",
    "train_label = train_label.sort_values('business_id')\n",
    "train_label = train_label.reset_index(drop=True)\n",
    "train_bid_features['labels'] = train_label['labels']\n",
    "\n",
    "# Find NaN label values and remove the row\n",
    "nan_label_indices = pd.isnull(train_bid_features).any(1).nonzero()[0]\n",
    "train_bid_features = train_bid_features.drop(train_bid_features.index[list(nan_label_indices)])\n",
    "\n",
    "# Check if the data frame is well constructed\n",
    "train_bid_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last step in feature extraction model is to saving the Extracted features using pickle model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the manipulated train & test data sets in pickle for preserving array format and considering its size\n",
    "train_bid_features.to_pickle('train_set_inception_v3.csv')\n",
    "test_bid_features.to_pickle('test_set_inception_v3.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
