{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3. Construct a classifier\n",
    "Boosting Algorithms and Importance of XGBoosting \n",
    "The name xgboost, though, actually refers to the engineering goal to push the limit of computations resources for boosted tree algorithms. Which is the reason why many people use xgboost.\n",
    "\n",
    "Gradient Boosting algorithm also called gradient boosting machine including the learning rate.\n",
    "Stochastic Gradient Boosting with sub-sampling at the row, column and column per split levels.\n",
    "Regularized Gradient Boosting with both L1 and L2 regularization.\n",
    "\n",
    "The two reasons to use XGBoost are also the two goals of the project:\n",
    "\n",
    "1.Execution Speed.\n",
    "2.Model Performance.\n",
    "\n",
    "The XGBoost library implements the gradient boosting decision tree algorithm\n",
    "\n",
    "Link:-https://en.wikipedia.org/wiki/Gradient_boosting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load manipulated data set\n",
    "train_df = pd.read_pickle(\"train_set.csv\")\n",
    "test_df  = pd.read_pickle(\"test_set.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (1996, 2048)\n",
      "Y_train:  (1996,)\n",
      "X_test:  (10000, 2048)\n"
     ]
    }
   ],
   "source": [
    "# Function to make labels in the data frame into a list (i.e. 0 8 => [0, 8])\n",
    "def labels_to_list(labels): return list(map(int, labels.split()))\n",
    "\n",
    "# Process train & test set into an array format\n",
    "X_train = np.array([x for x in train_df['features']])\n",
    "Y_train = np.array([labels_to_list(y) for y in train_df['labels']])\n",
    "X_test = np.array([x for x in test_df['features']])\n",
    "\n",
    "# Check shape of array-format train & test set\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"Y_train: \", Y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labeling is the process of encoding Different categories.\n",
    "\n",
    "We have main two approchs for labeling categorical data 1.LabelEncoder for encoding two label data like M/F Distiguation 2.one hot encoding is process of encoding label with considering dependency there is no correlation between previous labels and present labels. In this problem we need one-hot encoding for the multilable classificatin problem so we are using Multilabelbinarizer for encoding the categorical data.\n",
    "\n",
    "Advantages and disadvantages of encoding:\n",
    "\n",
    "1.Label encoding will not enhance dimensionality of dataset 2.But By using one-hot encoding we are getting high dimensionality of dataset but we can do dimensionality reduction using PCA to select principle components of high variance features so that computational time will reduce for training the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages for splitting train & validation set, XGBoost classifier, 1-of-K encoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Package for estimating a time taken\n",
    "import time; t=time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Traning Process:\n",
    "\n",
    "1.Traning is important process of Machine learning phase its important to handle the overfitting and underfitting when we training the model using classifier. splitting the dataset to train and test splits is important we have different splitting methodoligies for overcomming overfitting and under fitting probelm Ex:- K-fold cross validation and train_test_split are commonly used methods for overcomming overfitting fitting problem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  4373.469 sec\n"
     ]
    }
   ],
   "source": [
    "# Convert list of labels to follow 1-of-K coding scheme\n",
    "one_of_K_encoder = MultiLabelBinarizer()\n",
    "Y_train_ = one_of_K_encoder.fit_transform(Y_train)\n",
    "\n",
    "# Split train set into 8:2 (train : validation)\n",
    "random_state = np.random.RandomState(1040941203)\n",
    "X_train_, X_test_, Y_train_, Y_test_ = train_test_split(X_train, Y_train_, test_size=0.2, random_state=random_state)\n",
    "\n",
    "# Train the XGBoost classifier\n",
    "classifier = OneVsRestClassifier(XGBClassifier(num_class=9, gamma=0.024, learning_rate=0.3, max_depth=6, nthread=4, n_estimators=1000, objective=\"multi:softmax\"))\n",
    "classifier.fit(X_train_, Y_train_)\n",
    "\n",
    "# Predict labels using the trained model\n",
    "Y_predict = classifier.predict(X_test_)\n",
    "\n",
    "# Show spent time\n",
    "print(\"Time passed: \", \"{0:.3f}\".format(time.time() - t), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples of predicted labels (in binary matrix):\n",
      " [[0 1 1 0 0 1 1 0 0]\n",
      " [0 0 0 0 0 0 1 0 1]]\n",
      "\n",
      "Samples of predicted labels:\n",
      " [(1, 2, 5, 6), (6, 8)]\n"
     ]
    }
   ],
   "source": [
    "# Show some predicted values\n",
    "print(\"Samples of predicted labels (in 1-of-K coding scheme):\\n\", Y_predict[1:3])\n",
    "print(\"\\nSamples of corresponding predicted labels:\\n\", one_of_K_encoder.inverse_transform(Y_predict[1:3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we done labeling and model classification its good to test the classifier accuracy\n",
    "\n",
    "First we can see percentage of each lable prediction in prediction dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label 0</th>\n",
       "      <th>label 1</th>\n",
       "      <th>label 2</th>\n",
       "      <th>label 3</th>\n",
       "      <th>label 4</th>\n",
       "      <th>label 5</th>\n",
       "      <th>label 6</th>\n",
       "      <th>label 7</th>\n",
       "      <th>label 8</th>\n",
       "      <th>total_biz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biz_count</th>\n",
       "      <td>103</td>\n",
       "      <td>202</td>\n",
       "      <td>221</td>\n",
       "      <td>207</td>\n",
       "      <td>114</td>\n",
       "      <td>264</td>\n",
       "      <td>287</td>\n",
       "      <td>121</td>\n",
       "      <td>236</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biz_percentage</th>\n",
       "      <td>26%</td>\n",
       "      <td>50%</td>\n",
       "      <td>55%</td>\n",
       "      <td>52%</td>\n",
       "      <td>28%</td>\n",
       "      <td>66%</td>\n",
       "      <td>72%</td>\n",
       "      <td>30%</td>\n",
       "      <td>59%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label 0 label 1 label 2 label 3 label 4 label 5 label 6  \\\n",
       "biz_count          103     202     221     207     114     264     287   \n",
       "biz_percentage     26%     50%     55%     52%     28%     66%     72%   \n",
       "\n",
       "               label 7 label 8 total_biz  \n",
       "biz_count          121     236       400  \n",
       "biz_percentage     30%     59%      100%  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a data frame to show ratio of each label in a predicted set\n",
    "stat = pd.DataFrame(columns = ['label ' + str(i) for i in range(9)] + ['total_biz'], index = ['biz_count', 'biz_percentage'])\n",
    "\n",
    "stat.loc['biz_count'] = np.append(np.sum(Y_predict, axis=0), len(Y_predict))\n",
    "stat.loc['biz_percentage'] = stat.loc['biz_count'] * 100 / len(Y_predict) \n",
    "\n",
    "pd.options.display.float_format = '{:.0f}%'.format\n",
    "\n",
    "# Show the statistics\n",
    "stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The F1 Score is the 2((precision ) (recall)/(precision+recall)). Link for reference: https://en.wikipedia.org/wiki/F1_score Importance of using F1 Score precision:- Precision is the number of True Positives divided by the number of True Positives and False Positives Recall: Recall is the number of True Positives divided by the number of True Positives and the number of False Negatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.8349900596421471\n",
      "Individual Class F1 score:  [0.66666667 0.83538084 0.88735632 0.66666667 0.77118644 0.88593156\n",
      " 0.95017794 0.79518072 0.875     ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score # For measuring F1 score metrics\n",
    "\n",
    "# Show global F1 score & on-label F1 score\n",
    "print(\"Overall F1 score: \", f1_score(Y_test_, Y_predict, average='micro')) \n",
    "print(\"F1 score of each label : \", f1_score(Y_test, y_ppredict, average=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time passed:  5864.1 sec\n"
     ]
    }
   ],
   "source": [
    "t = time.time()\n",
    "\n",
    "# Convert list of labels to follow 1-of-K coding scheme\n",
    "one_of_K_encoder = MultiLabelBinarizer()\n",
    "Y_train_ = one_of_K_encoder.fit_transform(Y_train)\n",
    "\n",
    "# Train the SVM classifier again with a full train set\n",
    "random_state = np.random.RandomState(0)\n",
    "classifier = OneVsRestClassifier(XGBClassifier(num_class=9, gamma=0.024, learning_rate=0.3, max_depth=6, nthread=4, n_estimators=1000, objective=\"multi:softmax\"))\n",
    "classifier.fit(X_train, Y_train_)\n",
    "\n",
    "Y_predict = classifier.predict(X_test)\n",
    "Y_predict_label = one_of_K_encoder.inverse_transform(Y_predict)\n",
    "\n",
    "print(\"Time passed: \", \"{0:.1f}\".format(time.time() - t), \"sec\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Doing classification Analysis and accuracy measure we can transform the one-hot prediction labels to normal labeling form we can use inverse_transfrom of predicted label for total submittion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label 0</th>\n",
       "      <th>label 1</th>\n",
       "      <th>label 2</th>\n",
       "      <th>label 3</th>\n",
       "      <th>label 4</th>\n",
       "      <th>label 5</th>\n",
       "      <th>label 6</th>\n",
       "      <th>label 7</th>\n",
       "      <th>label 8</th>\n",
       "      <th>total_biz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>biz_count</th>\n",
       "      <td>760</td>\n",
       "      <td>7663</td>\n",
       "      <td>8446</td>\n",
       "      <td>7482</td>\n",
       "      <td>1540</td>\n",
       "      <td>9084</td>\n",
       "      <td>9344</td>\n",
       "      <td>2097</td>\n",
       "      <td>6547</td>\n",
       "      <td>10000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biz_percentage</th>\n",
       "      <td>8%</td>\n",
       "      <td>77%</td>\n",
       "      <td>84%</td>\n",
       "      <td>75%</td>\n",
       "      <td>15%</td>\n",
       "      <td>91%</td>\n",
       "      <td>93%</td>\n",
       "      <td>21%</td>\n",
       "      <td>65%</td>\n",
       "      <td>100%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               label 0 label 1 label 2 label 3 label 4 label 5 label 6  \\\n",
       "biz_count          760    7663    8446    7482    1540    9084    9344   \n",
       "biz_percentage      8%     77%     84%     75%     15%     91%     93%   \n",
       "\n",
       "               label 7 label 8 total_biz  \n",
       "biz_count         2097    6547     10000  \n",
       "biz_percentage     21%     65%      100%  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a data frame to show ratio of each label in a predicted set\n",
    "stat = pd.DataFrame(columns=['label ' + str(i) for i in range(9)] + ['total_biz'], index = ['biz_count', 'biz_percentage'])\n",
    "\n",
    "stat.loc['biz_count'] = np.append(np.sum(Y_predict, axis=0), len(Y_predict))\n",
    "stat.loc['biz_percentage'] = stat.loc[\"biz_count\"] * 100 / len(Y_predict)\n",
    "\n",
    "pd.options.display.float_format = '{:.0f}%'.format\n",
    "\n",
    "stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct a data frame for submission (matching predicted label with business id in a test set)\n",
    "final_df = pd.DataFrame(columns=['business_id','labels'])\n",
    "\n",
    "for i in range(len(test_df)):\n",
    "    biz = test_df.loc[i]['business_id']\n",
    "    label = Y_predict_label[i]\n",
    "    label = str(label)[1:-1].replace(\",\", \" \")\n",
    "    \n",
    "    final_df.loc[i] = [str(biz), label]\n",
    "\n",
    "# Write a submission file\n",
    "with open(\"Harish_project_work.csv\",'w') as file:\n",
    "    final_df.to_csv(file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
